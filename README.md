# Chatbot V0 â€” Next.js + FastAPI (Agent IA)

Prototype de chatbot **full-stack** :
- **Frontend** : Next.js (React + TypeScript + Tailwind)
- **Backend** : FastAPI (Python) + Agent IA (OpenAI)
- (BientÃ´t) RAG : LlamaIndex + Qdrant
- (BientÃ´t) MÃ©moire : Redis / Postgres
- (BientÃ´t) Actions : Make / APIs internes.

---

## ğŸ—‚ï¸ Structure du projet

```
chatbot-v0/
  frontend/          # UI Chat (Next.js)
  backend/           # API + agent IA (FastAPI)
  README.md
  .gitignore
```

---

## ğŸ“š Guide de lecture du repo (ce qui a Ã©tÃ© fait)

Cette section documente prÃ©cisÃ©ment les points clÃ©s du repo pour que vous puissiez lire et comprendre rapidement le code modifiÃ©.

### 1) Multilingue intelligent (FR/EN/AR)

- DÃ©tection automatique de la langue via LLM cÃ´tÃ© backend (fr | en | ar), avec repli simple si nÃ©cessaire.
  - ImplÃ©mentation: [backend/main.py](backend/main.py)
  - Fonctions clÃ©s:
    - `normalize_lang()` / `detect_language()` pour la normalisation et repli simple
    - `llm_detect_language(text)` pour la dÃ©tection par modÃ¨le
    - Dictionnaires `I18N` et `LANG_NAMES` pour les messages localisÃ©s
- RÃ©ponses du bot toujours dans la langue choisie/dÃ©tectÃ©e
  - Une consigne â€œsystemâ€ est ajoutÃ©e aux messages OpenAI pour forcer la langue et ne pas traduire les donnÃ©es sensibles (noms, numÃ©ros, dates)
- SÃ©lection manuelle possible via le frontend (select FR/EN/AR) ou en envoyant un message `FR`/`EN`/`AR`.

Frontend (UI localisÃ©e + RTL arabe):
- SÃ©lecteur de langue, greeting, labels, boutons, placeholders, titres des piÃ¨ces jointes localisÃ©s
- Passage RTL automatique pour lâ€™arabe
- Fichier: [frontend/app/page.tsx](frontend/app/page.tsx)
- Composant piÃ¨ces jointes internationalisÃ©: [frontend/components/FileSlot.tsx](frontend/components/FileSlot.tsx)

### 2) Comment le frontend appelle le backend

- URL: `POST http://127.0.0.1:8000/chat`
- Corps: `multipart/form-data` avec:
  - `messages`: string JSON (tableau de `{ role, content }`)
  - `session_id`: string (stockÃ© dans localStorage)
  - `language`: string optionnel (`fr` | `en` | `ar`) pour forcer la session
  - `prescription_file`, `insurance_file`: fichiers optionnels (PDF / image)
- ImplÃ©mentation cÃ´tÃ© UI: [frontend/app/page.tsx](frontend/app/page.tsx)

### 2.1) RAG Q/R (FAQ csv) â€” comment Ã§a marche

Objectif: permettre au bot de rÃ©pondre Ã  partir dâ€™un fichier CSV de questions/rÃ©ponses (FAQ interne), en FR/EN/AR.

Chargement & nettoyage
- Placez votre fichier source dans `backend/QR.csv` (par dÃ©faut) ou dÃ©finissez `RAG_CSV_PATH` dans `backend/.env`.
- Le parseur dÃ©tecte encodage (UTFâ€‘8 â†’ CP1252 en repli) et dÃ©limiteur (prioritÃ© `;`, sinon `,`).
- Les colonnes Q/R sont dÃ©tectÃ©es par lâ€™enâ€‘tÃªte (`question|quest` et `rÃ©ponse|repon|answer`). Si absent, on prend les 2 derniÃ¨res cellules non vides de chaque ligne.
- Endpoint de nettoyage: `POST /rag/clean` â†’ gÃ©nÃ¨re `backend/QR_clean.csv` en UTFâ€‘8 avec 2 colonnes standard `question,answer` et recharge lâ€™index.
- DÃ©marrage: le serveur charge `RAG_CSV_PATH` sâ€™il est lisible; sinon il essaie automatiquement `QR_clean.csv`.

Endpoints RAG
- `GET /rag/status` â†’ `{ count, config_path, loaded_path }`
- `POST /rag/clean` â†’ nettoie `QR.csv` en `QR_clean.csv` + recharge; renvoie `{ ok, src, dst, count, reloaded }`
- `POST /rag/reload` â†’ recharge lâ€™index (facultatif, avec `?path=...`)
- `POST /rag/ask` â†’ rÃ©pond uniquement depuis le CSV. Form-data: `q` (question), `language` (optionnel: `fr|en|ar`). Retour: `{ answer, matched_question, lang }`
- `GET /rag/debug?q=...` â†’ debug: montre les meilleurs matchs lexicaux (scores + Q/A)

StratÃ©gie de recherche (retrieval)
- Chemin rapide (exact/proche): si la question de lâ€™utilisateur correspond de trÃ¨s prÃ¨s Ã  une Q du CSV, on renvoie directement la rÃ©ponse du CSV (sans appeler le LLM). SimilaritÃ© lexicale normalisÃ©e (accents retirÃ©s), seuil â‰ˆ 0.85 + boost sur sousâ€‘chaÃ®ne/exact.
- Sinon: rÃ©cupÃ©ration hybride
  - Embeddings calculÃ©s Ã  la demande (pas au dÃ©marrage) pour question et documents;
  - Repli lexical rapide si lâ€™API dâ€™embeddings nâ€™est pas disponible.
- Les meilleurs extraits (Q/A) sont ensuite injectÃ©s dans le contexte du LLM si besoin.

Langue des rÃ©ponses
- La langue de rÃ©ponse est strictement celle de la session (FR/EN/AR). Si la rÃ©ponse CSV est en FR et la session en EN/AR, elle est traduite automatiquement avant affichage (noms/numÃ©ros/dates non traduits).

Variables dâ€™env utiles (backend/.env)
```
RAG_CSV_PATH=QR.csv           # ou QR_clean.csv si vous voulez forcer le fichier nettoyÃ©
OPENAI_EMBED_MODEL=text-embedding-3-small
RAG_USE_EMBED=false           # par dÃ©faut: retrieval lexical sans embeddings
RAG_TRANSLATE=false           # traduire la rÃ©ponse CSV vers la langue cible (si true)
LANG_USE_LLM=false            # activer la dÃ©tection de langue par LLM (sinon heuristique rapide)
```

Bonnes pratiques CSV
- Une question courte et claire; une rÃ©ponse concise.
- Ã‰vitez les sauts de ligne dans les cellules; si besoin, utilisez le nettoyage pour standardiser.
- Si votre source comporte beaucoup de colonnes, assurezâ€‘vous que les deux derniÃ¨res non vides sont bien (Q, A) ou nommez les colonnes Â« Question Â» et Â« RÃ©ponse Â».

### 3) Endpoints FastAPI

- `GET /health` â†’ simple statut
- `POST /chat` â†’ logique principale du chatbot (flow location + fallback IA)
  - ParamÃ¨tres `Form`: `messages`, `session_id`, `language`
  - ParamÃ¨tres `File`: `prescription_file`, `insurance_file`
  - RÃ©ponse: `{ reply: string, session_id: string }`
- `GET /lang/detect?text=...` â†’ helper dev: renvoie `{ language: fr|en|ar }`
- `POST /rag/ask` â†’ rÃ©pond depuis la base CSV (voir 2.1)
- `GET /rag/debug` â†’ diagnostic matching (voir 2.1)
- CORS: autorise http://localhost:3000
- ImplÃ©mentation: [backend/main.py](backend/main.py)

### 3.1) Mode â€œQuestion/Aideâ€ (UI)

- Dans lâ€™UI, un bouton â€œQuestion/Aideâ€ est disponible Ã  deux endroits:
  - Dans les actions rapides (Ã  cÃ´tÃ© de Bonjour/Location/Ordonnance)
  - Dans lâ€™entÃªte du slot â€œOrdonnanceâ€ (quand la section PJ est visible)
- Comportement:
  1. Au clic, le bot affiche un prompt localisÃ© (FR/EN/AR): â€œComment puis-je vous aider ? â€¦â€
  2. Les messages suivants sont routÃ©s vers `POST /rag/ask` et rÃ©pondus uniquement depuis la base CSV (RAG). Pas dâ€™appel LLM.
  3. Le mode se dÃ©sactive si vous lancez la â€œLocationâ€ ou si vous faites â€œRÃ©initialiserâ€.
- La langue UI est envoyÃ©e Ã  `/rag/ask` pour obtenir une rÃ©ponse traduite si `RAG_TRANSLATE=true`.

### 4) Sessions et mÃ©moire en RAM

- Dictionnaire en mÃ©moire `SESSIONS` indexÃ© par `session_id`
- Contenu par session:
  - `lang`: langue choisie/dÃ©tectÃ©e
  - `step`: Ã©tape du flow (`ASK_RENTAL_ALL` â†’ `CONFIRM_RENTAL`)
  - `data`: infos client + mÃ©tadonnÃ©es piÃ¨ces jointes (base64, filename, content_type)
  - `raw_intake`, `created_at`
- ImplÃ©mentation: [backend/main.py](backend/main.py)

### 5) Gestion des piÃ¨ces jointes

- Types autorisÃ©s: PDF, JPG, PNG, WebP (max 6 Mo)
- Backend: lecture, validation, encodage base64, stockage dans `SESSIONS[sid]['data']`
- Frontend: composant `FileSlot` localisÃ©, affichage automatique de la zone PJ quand le bot la demande (FR/EN/AR)
- ImplÃ©mentations:
  - Backend: [backend/main.py](backend/main.py)
  - Frontend: [frontend/app/page.tsx](frontend/app/page.tsx), [frontend/components/FileSlot.tsx](frontend/components/FileSlot.tsx)

### 6) Flow â€œLocation de tire-laitâ€

- DÃ©clencheurs multilingues (FR/EN/AR) dÃ©tectÃ©s dans le message utilisateur
- Ã‰tapes:
  1. Demande dâ€™info en un seul message + 2 PJ
  2. VÃ©rification automatique (LLM) + corrections Ã©ventuelles
  3. RÃ©capitulatif localisÃ© + confirmation â€œOUI/YES/Ù†Ø¹Ù…â€
  4. Envoi webhook (si `MAKE_WEBHOOK_URL` configurÃ©e)
- ImplÃ©mentation: [backend/main.py](backend/main.py)

---

## âš™ï¸ Configuration & Variables dâ€™environnement

Backend: `backend/.env`

```
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
MAKE_WEBHOOK_URL=   # optionnel
PROMPT_RELOAD=false # optionnel (1/true pour recharger le prompt system.md Ã  chaud)
# RAG / Langues
RAG_CSV_PATH=QR.csv        # ou QR_clean.csv
RAG_USE_EMBED=false        # retrieval lexical par dÃ©faut
RAG_TRANSLATE=false        # traduire la rÃ©ponse CSV vers la langue UI
LANG_USE_LLM=false         # detection LLM optionnelle (sinon heuristique)
```

Frontend: pas de .env requis pour la V0. Le sÃ©lecteur de langue persiste `tlx_lang` et la session `tlx_session_id` en localStorage.

---

## â–¶ï¸ DÃ©marrage rapide

1) Backend

```
cd backend
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
uvicorn main:app --reload --port 8000
```

2) Frontend

```
cd frontend
npm install
npm run dev
```

3) Ouvrir http://localhost:3000

- Ã‰crire en arabe/anglais/franÃ§ais â†’ le bot rÃ©pond dans la langue dÃ©tectÃ©e.
- Changer la langue via le sÃ©lecteur â†’ lâ€™UI et les rÃ©ponses basculent.
- Taper â€œlocationâ€/â€œrentalâ€/â€œØ§Ø³ØªØ¦Ø¬Ø§Ø±â€ â†’ le flow location dÃ©marre (FR/EN/AR).

---

## âœ… PrÃ©requis

- Node.js (LTS recommandÃ©)
- Python 3.11+
- Git
- (Optionnel) Docker Desktop â€” pour Qdrant/Redis/Postgres plus tard

VÃ©rifier lâ€™installation :

```bash
node -v
npm -v
python --version
git --version
```

---

## ğŸš€ Lancer le projet en local

âš ï¸ Ouvre **2 terminaux** : un pour le backend, un pour le frontend.

---

## 1ï¸âƒ£ Backend (FastAPI)

Aller dans le backend :

```bash
cd backend
```

CrÃ©er et activer lâ€™environnement virtuel (Windows) :

```bash
python -m venv .venv
.venv\Scripts\activate
```

Installer les dÃ©pendances :

```bash
pip install -r requirements.txt
```

Configurer les variables dâ€™environnement :

```bash
copy .env.example .env
```

Puis Ã©diter `backend/.env` :

```env
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_MODEL=gpt-4o-mini
```

Lancer le serveur :

```bash
uvicorn main:app --reload --port 8000
```

âœ… Swagger : http://127.0.0.1:8000/docs  
âœ… Healthcheck : http://127.0.0.1:8000/health  

---

## 2ï¸âƒ£ Frontend (Next.js)

Aller dans le frontend :

```bash
cd ../frontend
```

Installer les dÃ©pendances :

```bash
npm install
```

Lancer lâ€™app :

```bash
npm run dev
```

âœ… UI : http://localhost:3000  

---

## ğŸ”Œ API utilisÃ©e par le frontend

Le frontend appelle le backend sur :

- `POST http://127.0.0.1:8000/chat`

Format de requÃªte :

```json
{
  "messages": [
    { "role": "user", "content": "Bonjour" }
  ]
}
```

Format de rÃ©ponse :

```json
{
  "reply": "Bonjour ! Comment puis-je vous aider ?"
}
```

---

## ğŸ§ª Test manuel rapide

1) Lance backend + frontend  
2) Va sur http://localhost:3000  
3) Tape :
- Bonjour
- Je veux louer un tire-lait
- Mon code postal est 75011

---

## ğŸ” SÃ©curitÃ© (IMPORTANT)

âœ… Ne jamais commiter de secrets (clÃ© OpenAI).

Le fichier `backend/.env` est ignorÃ© via `.gitignore`.

Les collÃ¨gues doivent utiliser :
- `backend/.env.example` â†’ Ã  copier en `.env`

---

## ğŸ¤ Collaboration Git (recommandÃ©)

Branches :
- `main` : stable
- `feature/*` : nouvelles features
- `fix/*` : corrections

CrÃ©er une branche :

```bash
git checkout -b feature/nom-de-feature
```

Commit & push :

```bash
git add .
git commit -m "Describe your change"
git push -u origin feature/nom-de-feature
```

Ensuite ouvrir une **Pull Request** sur GitHub.

---

## ğŸ› ï¸ Troubleshooting

### âŒ Erreur "Failed to fetch" depuis le frontend
âœ… VÃ©rifie que FastAPI tourne : http://127.0.0.1:8000/docs  
âœ… VÃ©rifie que CORS autorise http://localhost:3000 (CORSMiddleware dans `main.py`).

### âŒ Port dÃ©jÃ  utilisÃ©
```bash
uvicorn main:app --reload --port 8001
```
Et change lâ€™URL dans le frontend.

### âŒ Imports Python en rouge dans IntelliJ
### âŒ Multilingue ne bascule pas
- VÃ©rifiez `/lang/detect?text=...` avec vos phrases (FR/EN/AR)
- Si vos phrases en franÃ§ais basculent en â€œenâ€, rajoutez des mots FR (ex: â€œbonjourâ€) ou forcez la langue via le sÃ©lecteur UI. Vous pouvez activer `LANG_USE_LLM=true` si nÃ©cessaire.

### âŒ â€œQuestion/Aideâ€ ne trouve pas de rÃ©ponse
- Ouvrez `/rag/debug?q=...` pour voir les meilleurs matchs et vÃ©rifier la colonne â€œanswerâ€.
- Nettoyez/rechargez: `POST /rag/clean` ou `POST /rag/reload`.

---

## ğŸ—“ï¸ Changelog â€“ 2026-02-02

Backend
- Chargement RAG fiabilisÃ©: embeddings Ã  la demande (optionnels), retrieval lexical robuste; fallback auto vers `QR_clean.csv` au dÃ©marrage.
- Parsing CSV tolÃ©rant encodage/dÃ©limiteur + dÃ©tection colonnes Q/R; endpoint `POST /rag/clean` pour produire `QR_clean.csv` UTFâ€‘8 (2 colonnes).
- Endpoints RAG:
  - `GET /rag/status` â†’ ajoute `config_path` et `loaded_path`
  - `POST /rag/reload` / `POST /rag/clean`
  - `POST /rag/ask` (Form: `q`, `language`) â†’ rÃ©ponse uniquement depuis CSV
  - `GET /rag/debug` â†’ diagnostic lexical (top scores + Q/A)
- Multilingue: heuristique renforcÃ©e (FR/EN/AR) + LLM optionnel (`LANG_USE_LLM`).
- Traduction optionnelle des rÃ©ponses CSV vers la langue cible (`RAG_TRANSLATE`).
- Hook FastAPI `startup` pour charger lâ€™index sans erreur dâ€™ordre dâ€™import.

Frontend
- Ajout du mode â€œQuestion/Aideâ€:
  - Bouton dans les actions rapides et Ã  cÃ´tÃ© dâ€™â€œOrdonnanceâ€.
  - Prompt â€œComment puis-je vous aider ?â€ puis rÃ©ponses via `/rag/ask` (CSV only).
  - Sortie du mode Ã  la â€œLocationâ€ ou â€œRÃ©initialiserâ€.
- Envoi de la langue UI vers `/rag/ask` pour rÃ©pondre dans la langue choisie.
- Bouton â€œQuestion/Aideâ€ cliquable mÃªme sans texte saisi.

Variables dâ€™env (nouveaux)
- `RAG_USE_EMBED`, `RAG_TRANSLATE`, `LANG_USE_LLM`, `RAG_CSV_PATH`.

Tests rapides
- `GET /rag/status` â†’ `count > 0`, `loaded_path` dÃ©fini
- `POST /rag/ask` (Form: q=â€œmon TL ne fonctionne plusâ€) â†’ rÃ©ponse CSV
- UI: cliquer â€œQuestion/Aideâ€ â†’ poser â€œle tl ne fonctionne pasâ€ â†’ rÃ©ponse trouvÃ©e
Configurer lâ€™interprÃ©teur :
- `backend\.venv\Scripts\python.exe`

---

## ğŸ§­ Roadmap

### âœ… V0
- [x] UI Next.js
- [x] Backend FastAPI
- [x] Endpoint `/chat`
- [x] IA via OpenAI (gpt-4o-mini)
- [x] Multilingue intelligent (FR/EN/AR) â€” dÃ©tection LLM + UI localisÃ©e

### ğŸ”œ V1
- [ ] Sessions + mÃ©moire (Redis/Postgres)
- [ ] Streaming rÃ©ponses
- [ ] Analytics (logs)

### ğŸ”œ V2
- [ ] RAG : LlamaIndex + Qdrant
- [ ] Ingestion docs + retrieval
- [ ] RÃ©ponses sourcÃ©es

### ğŸ”œ V3
- [ ] Actions (Make / APIs internes)
- [ ] Monitoring (Metabase + dashboard)
